{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O01-2MWSPGI1",
        "fMF6oeZhPa-S",
        "PvXTuUi0_VrN",
        "B9y3iyWb_hrS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dash\n",
        "!pip install dash_bootstrap_components"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJhQlt7oqvMt",
        "outputId": "144af67d-59ca-4e96-eb9b-de469f899a3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash\n",
            "  Downloading dash-2.17.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.15.0)\n",
            "Collecting dash-html-components==2.0.0 (from dash)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0 (from dash)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (7.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.31.0)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (67.7.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (8.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.16.0)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, dash\n",
            "Successfully installed dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 retrying-1.3.4\n",
            "Collecting dash_bootstrap_components\n",
            "  Downloading dash_bootstrap_components-1.6.0-py3-none-any.whl (222 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dash>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash_bootstrap_components) (2.17.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (3.0.3)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (5.15.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (5.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (7.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (2.31.0)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.0.0->dash_bootstrap_components) (67.7.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (8.1.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (8.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash>=2.0.0->dash_bootstrap_components) (2.1.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.0.0->dash_bootstrap_components) (3.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (2024.6.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash>=2.0.0->dash_bootstrap_components) (1.16.0)\n",
            "Installing collected packages: dash_bootstrap_components\n",
            "Successfully installed dash_bootstrap_components-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importation des librarry"
      ],
      "metadata": {
        "id": "O01-2MWSPGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "from dash.dependencies import Input, Output\n",
        "import base64\n",
        "import nest_asyncio\n",
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html\n",
        "import dash_bootstrap_components as dbc\n",
        "import base64\n",
        "import nest_asyncio\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import io\n"
      ],
      "metadata": {
        "id": "CXIwnzzi_Uw0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaping web"
      ],
      "metadata": {
        "id": "fMF6oeZhPa-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**site de ansm**"
      ],
      "metadata": {
        "id": "oitlcn0fPf_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# DataFrame pour stocker les résultats\n",
        "df = pd.DataFrame(columns=['Title', 'Author', 'Date', 'Number of Responses', 'Content'])\n",
        "\n",
        "def scrape_post_content(post_url):\n",
        "    response = requests.get(post_url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    post_content_tag = soup.find('div', class_='bbWrapper')\n",
        "    post_content = post_content_tag.text.strip() if post_content_tag else \"No content found\"\n",
        "    return post_content\n",
        "\n",
        "def scrape_forum_page(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Les threads\n",
        "    threads = soup.find_all('div', class_='structItem--thread')\n",
        "\n",
        "    for thread in threads:\n",
        "        title_tag = thread.find('div', class_='structItem-title')\n",
        "        title = title_tag.text.strip()\n",
        "        author = thread.find('a', class_='username').text.strip()\n",
        "        date = thread.find('time')['datetime']\n",
        "\n",
        "        # Nombre de réponses\n",
        "        response_count_tag = thread.find('dl', class_='pairs pairs--justified structItem-minor')\n",
        "        if response_count_tag:\n",
        "            response_counts = response_count_tag.find_all('dd')\n",
        "            if len(response_counts) > 1:\n",
        "                num_responses = response_counts[1].text.strip()\n",
        "            else:\n",
        "                num_responses = '0'\n",
        "        else:\n",
        "            num_responses = '0'\n",
        "\n",
        "        # Ontention complet du post\n",
        "        post_url = 'https://forum.alzheimers.org.uk' + title_tag.find('a')['href']\n",
        "        content = scrape_post_content(post_url)\n",
        "\n",
        "        # Les données au DataFrame\n",
        "        df.loc[len(df)] = [title, author, date, num_responses, content]\n",
        "\n",
        "# Les 30 premières pages (600 postes)\n",
        "base_url = 'https://forum.alzheimers.org.uk/forums/i-have-dementia.56/page-{}.html'\n",
        "for page_num in range(1, 31):\n",
        "    url = base_url.format(page_num)\n",
        "    print(f'Scraping page {page_num}...')\n",
        "    scrape_forum_page(url)\n",
        "    time.sleep(1)\n",
        "\n",
        "# Fichier CSV\n",
        "df.to_csv('forum_posts_30_pages.csv', index=False)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4jMrw289EeT",
        "outputId": "bd4a1cb2-4e48-4609-af05-fa40e272b7e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n",
            "Scraping page 4...\n",
            "Scraping page 5...\n",
            "Scraping page 6...\n",
            "Scraping page 7...\n",
            "Scraping page 8...\n",
            "Scraping page 9...\n",
            "Scraping page 10...\n",
            "Scraping page 11...\n",
            "Scraping page 12...\n",
            "Scraping page 13...\n",
            "Scraping page 14...\n",
            "Scraping page 15...\n",
            "Scraping page 16...\n",
            "Scraping page 17...\n",
            "Scraping page 18...\n",
            "Scraping page 19...\n",
            "Scraping page 20...\n",
            "Scraping page 21...\n",
            "Scraping page 22...\n",
            "Scraping page 23...\n",
            "Scraping page 24...\n",
            "Scraping page 25...\n",
            "Scraping page 26...\n",
            "Scraping page 27...\n",
            "Scraping page 28...\n",
            "Scraping page 29...\n",
            "Scraping page 30...\n",
            "                                               Title    Author  \\\n",
            "0               Your advice - Appointing an attorney   TamsinT   \n",
            "1  Webinars delivered by people living with dementia  HarrietD   \n",
            "2                                     Hints and Tips     Pejic   \n",
            "3  The dementia guide: for people dealing with a ...  HarrietD   \n",
            "4                    I don’t know how to handle this     Nobo2   \n",
            "\n",
            "                       Date Number of Responses  \\\n",
            "0  2024-06-05T15:16:36+0100                   0   \n",
            "1  2024-01-11T12:11:28+0000                   0   \n",
            "2  2022-08-18T18:17:16+0100                   0   \n",
            "3  2021-05-05T13:30:02+0100                   0   \n",
            "4  2024-06-13T22:41:06+0100                   0   \n",
            "\n",
            "                                             Content  \n",
            "0  Do you have any tips for other people with dem...  \n",
            "1  Hi everyone,\\n\\nWe wanted to let you know that...  \n",
            "2  Any chance of making this a sticky thread, we ...  \n",
            "3  Have you recently been diagnosed with dementia...  \n",
            "4  Hi everyone, it’s been just over a year since ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forum alzheimer's Society**"
      ],
      "metadata": {
        "id": "eoC39vppPpwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd\n",
        "import urllib3\n",
        "\n",
        "urllib3.disable_warnings()\n",
        "\n",
        "url_list = [\n",
        "    'https://data.ansm.sante.fr/specialite/62650485',\n",
        "    'https://data.ansm.sante.fr/specialite/68673252',\n",
        "    'https://data.ansm.sante.fr/specialite/66072114'\n",
        "]\n",
        "\n",
        "All_data_med = []\n",
        "x = 0\n",
        "\n",
        "# DataFrames pour stocker les données\n",
        "df_medications = pd.DataFrame(columns=[\n",
        "    'Nom_medicament', 'Estimation',\n",
        "    'Hommes (%)',\n",
        "    'Femmes (%)',\n",
        "    '20-59 (%)',\n",
        "    '60+ (%)',\n",
        "    'Période_min', 'Période_max',\n",
        "    'Total_declarations',\n",
        "    'Hommes_decl (%)',\n",
        "    'Femmes_decl (%)'\n",
        "])\n",
        "df_effects = pd.DataFrame(columns=[\n",
        "    'Nom_medicament', 'Pathologie', 'Valeur'\n",
        "])\n",
        "\n",
        "for url in url_list:\n",
        "    html_content = requests.get(url, verify=False).text\n",
        "    soup = BeautifulSoup(html_content, \"lxml\")\n",
        "\n",
        "    # Extraction des informations de base\n",
        "    Nom_medicament = soup.find('div', attrs={'class': 'text-xl lg:text-2xl font-medium mb-4'})\n",
        "    Estimation = soup.find('h3', attrs={'class': 'text-2xl text-primary'})\n",
        "\n",
        "    if Nom_medicament:\n",
        "        Nom_medicament = Nom_medicament.string\n",
        "    else:\n",
        "        Nom_medicament = \"Unknown\"\n",
        "\n",
        "    if Estimation:\n",
        "        Estimation = Estimation.string\n",
        "    else:\n",
        "        Estimation = \"Unknown\"\n",
        "\n",
        "    script = soup.find('script', attrs={'id': \"__NEXT_DATA__\"}).string\n",
        "    script2 = json.loads(script)\n",
        "\n",
        "    Nom_medicament = script2[\"props\"][\"pageProps\"][\"cis\"]['name']\n",
        "\n",
        "    pat_trait_hom = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0][\"repartitionPerGender\"][\"male\"]\n",
        "    pat_trait_fem = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0][\"repartitionPerGender\"][\"female\"]\n",
        "\n",
        "    age_data = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['repartitionPerAge']\n",
        "    age_20_59 = age_data[0] if len(age_data) > 0 else {'range': '20-59', 'valuePercent': None}\n",
        "    age_60_p = age_data[1] if len(age_data) > 1 else {'range': '60+', 'valuePercent': None}\n",
        "\n",
        "    periode_effects = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['sideEffects'][\"bnpvPeriod\"]\n",
        "    total_declarations = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['sideEffects'][\"declarations\"][\"total\"]\n",
        "\n",
        "    decl_hom = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['sideEffects'][\"repartitionPerGender\"][\"male\"]\n",
        "    decl_fem = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['sideEffects'][\"repartitionPerGender\"][\"female\"]\n",
        "\n",
        "    # Les données démographiques au DataFrame\n",
        "    new_row = {\n",
        "        'Nom_medicament': Nom_medicament,\n",
        "        'Estimation': Estimation,\n",
        "        'Hommes (%)': pat_trait_hom['valuePercent'],\n",
        "        'Femmes (%)': pat_trait_fem['valuePercent'],\n",
        "        '20-59 (%)': age_20_59['valuePercent'],\n",
        "        '60+ (%)': age_60_p['valuePercent'],\n",
        "        'Période_min': periode_effects['minYear'],\n",
        "        'Période_max': periode_effects['maxYear'],\n",
        "        'Total_declarations': total_declarations,\n",
        "        'Hommes_decl (%)': decl_hom['valuePercent'],\n",
        "        'Femmes_decl (%)': decl_fem['valuePercent']\n",
        "    }\n",
        "\n",
        "    df_medications = pd.concat([df_medications, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "    # Les effets indésirables au DataFrame\n",
        "    side_effects = script2[\"props\"][\"pageProps\"][\"cis\"][\"substances\"][0]['sideEffects']['repartitionPerPathology']\n",
        "    for effect in side_effects:\n",
        "        new_effect = {\n",
        "            'Nom_medicament': Nom_medicament,\n",
        "            'Pathologie': effect['range'],\n",
        "            'Valeur': effect['value']\n",
        "        }\n",
        "        df_effects = pd.concat([df_effects, pd.DataFrame([new_effect])], ignore_index=True)\n",
        "\n",
        "# Fichiers CSV\n",
        "df_medications.to_csv('medications.csv', index=False)\n",
        "df_effects.to_csv('effects.csv', index=False)\n",
        "\n",
        "# Vérification\n",
        "print(df_medications.head())\n",
        "print(df_effects.head())\n"
      ],
      "metadata": {
        "id": "dJG0DHWl-s4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b655930-660f-4c8a-b696-08d057dda494"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Nom_medicament  \\\n",
            "0                  Aricept 10 mg, comprimé pelliculé   \n",
            "1  Galantamine biogaran lp 16 mg, gélule à libéra...   \n",
            "2       Memantine biogaran 20 mg, comprimé pelliculé   \n",
            "\n",
            "                 Estimation  Hommes (%)  Femmes (%)  20-59 (%)  60+ (%)  \\\n",
            "0   Estimation : 4 000 / an        31.5        68.3        1.2     98.7   \n",
            "1   Estimation : 3 000 / an        32.9        66.9        0.7     99.2   \n",
            "2  Estimation : 10 000 / an        32.1        67.8        0.8     99.1   \n",
            "\n",
            "  Période_min Période_max Total_declarations  Hommes_decl (%)  Femmes_decl (%)  \n",
            "0        2014        2023                162             36.4             63.6  \n",
            "1        2014        2023                129             44.2             55.8  \n",
            "2        2014        2023                408             41.2             58.8  \n",
            "                      Nom_medicament  \\\n",
            "0  Aricept 10 mg, comprimé pelliculé   \n",
            "1  Aricept 10 mg, comprimé pelliculé   \n",
            "2  Aricept 10 mg, comprimé pelliculé   \n",
            "3  Aricept 10 mg, comprimé pelliculé   \n",
            "4  Aricept 10 mg, comprimé pelliculé   \n",
            "\n",
            "                                      Pathologie Valeur  \n",
            "0                          Affections cardiaques     16  \n",
            "1  Affections de la peau et du tissu sous-cutané     15  \n",
            "2                  Affections du système nerveux     54  \n",
            "3                 Affections gastro-intestinales     19  \n",
            "4                      Affections psychiatriques     24  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse des tables effects et medications"
      ],
      "metadata": {
        "id": "PvXTuUi0_VrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Les données depuis les fichiers CSV\n",
        "df_medications = pd.read_csv('/content/medications.csv')\n",
        "df_effects = pd.read_csv('/content/effects.csv')\n",
        "\n",
        "# Préparation des données pour les graphiques\n",
        "def prepare_data():\n",
        "    df_medications['Nom_du_médicament'] = df_medications['Nom_medicament'].str.split().str[0]\n",
        "    df_sex_distribution = df_medications.groupby('Nom_du_médicament')[['Hommes (%)', 'Femmes (%)']].mean().reset_index()\n",
        "    df_age_distribution = df_medications.groupby('Nom_du_médicament')[['20-59 (%)', '60+ (%)']].mean().reset_index()\n",
        "    df_effects['Nom_du_médicament'] = df_effects['Nom_medicament'].str.split().str[0]\n",
        "    df_effects_count = df_effects.groupby(['Nom_du_médicament', 'Pathologie'])['Valeur'].sum().reset_index()\n",
        "\n",
        "    return df_sex_distribution, df_age_distribution, df_effects_count\n",
        "\n",
        "df_sex_distribution, df_age_distribution, df_effects_count = prepare_data()\n"
      ],
      "metadata": {
        "id": "3DV2XCAK_Rkk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4xk5qqnv_gQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP"
      ],
      "metadata": {
        "id": "B9y3iyWb_hrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Les ressources nécessaires pour nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Chargement des données depuis les fichiers CSV\n",
        "df_posts = pd.read_csv('/content/forum_posts_30_pages.csv')\n",
        "df_medications = pd.read_csv('/content/medications.csv')\n",
        "df_effects = pd.read_csv('/content/effects.csv')\n",
        "\n",
        "# Les valeurs de la colonne 'Content' en chaînes de caractères\n",
        "df_posts['Content'] = df_posts['Content'].astype(str)\n",
        "\n",
        "# Les fonctions de nettoyage\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', text)\n",
        "\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        '['\n",
        "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
        "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
        "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
        "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
        "        u'\\U00002702-\\U000027B0'\n",
        "        u'\\U000024C2-\\U0001F251'\n",
        "        ']+',\n",
        "        flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
        "    return re.sub(html, '', text)\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "def remove_newlines(text):\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def remove_digits(text):\n",
        "    text = re.sub(r'\\d', '', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convertir en minuscules\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text)\n",
        "    text = ' '.join([token for token in tokens if token not in stop_words])\n",
        "    return text\n",
        "\n",
        "stemmer = SnowballStemmer('english')\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Appliquation des fonctions de nettoyage aux posts du forum\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_URL(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_emoji(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_html(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_punct(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_newlines(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: remove_digits(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: clean_text(x))\n",
        "df_posts['Content'] = df_posts['Content'].apply(lambda x: lemmatize_stemming(x))\n",
        "\n",
        "\n",
        "big_text = ' '.join(df_posts['Content'].tolist())\n",
        "\n",
        "# Liste des effets indésirables\n",
        "effects_list = [\n",
        "    \"nausea\", \"vomiting\", \"headache\", \"dizziness\", \"fatigue\",\n",
        "    \"abdominal pain\", \"diarrhea\", \"constipation\", \"loss of appetite\",\n",
        "    \"muscle pain\", \"muscle spasms\", \"skin rash\", \"itching\", \"redness\",\n",
        "    \"excessive sweating\", \"fever\", \"palpitations\", \"hypertension\",\n",
        "    \"hypotension\", \"tachycardia\", \"bradycardia\", \"anemia\", \"weight loss\",\n",
        "    \"weight gain\", \"swelling\", \"joint pain\", \"back pain\", \"chills\",\n",
        "    \"dry mouth\", \"metallic taste\", \"increased thirst\", \"increased urination\",\n",
        "    \"difficulty swallowing\", \"chest tightness\", \"tingling\", \"numbness\",\n",
        "    \"lightheadedness\", \"malaise\", \"fatigue\", \"weakness\", \"tremors\",\n",
        "    \"insomnia\", \"drowsiness\", \"confusion\", \"anxiety\", \"depression\",\n",
        "    \"agitation\", \"tremors\", \"seizures\", \"memory loss\", \"balance disorders\",\n",
        "    \"blurred vision\", \"restlessness\", \"panic attacks\", \"irritability\",\n",
        "    \"hallucinations\", \"nightmares\", \"paranoia\", \"mood swings\", \"delirium\",\n",
        "    \"dysarthria\", \"dystonia\", \"neuralgia\", \"paresthesia\", \"syncope\",\n",
        "    \"stomach pain\", \"bloating\", \"acid reflux\", \"gastric ulcers\",\n",
        "    \"indigestion\", \"flatulence\", \"belching\", \"heartburn\", \"intestinal gas\",\n",
        "    \"bloody stools\", \"black stools\", \"jaundice\", \"liver dysfunction\",\n",
        "    \"pancreatitis\", \"hepatitis\", \"colitis\", \"enteritis\",\n",
        "    \"difficulty breathing\", \"shortness of breath\", \"cough\", \"nasal congestion\",\n",
        "    \"wheezing\", \"sinusitis\", \"respiratory infection\", \"bronchospasm\",\n",
        "    \"pneumonia\", \"dry throat\", \"hoarseness\", \"pharyngitis\", \"laryngitis\",\n",
        "    \"asthma\", \"emphysema\", \"pleurisy\",\n",
        "    \"hives\", \"dry skin\", \"hair loss\", \"eczema\", \"acne\", \"blisters\",\n",
        "    \"photosensitivity\", \"skin discoloration\", \"bruising\", \"peeling skin\",\n",
        "    \"dermatitis\", \"psoriasis\", \"alopecia\", \"urticaria\",\n",
        "    \"chest pain\", \"heart attack\", \"stroke\", \"high blood pressure\",\n",
        "    \"low blood pressure\", \"arrhythmia\", \"peripheral edema\", \"venous thrombosis\",\n",
        "    \"heart palpitations\", \"heart failure\", \"angina\", \"myocarditis\",\n",
        "    \"pericarditis\", \"varicose veins\", \"hypertension\",\n",
        "    \"kidney pain\", \"urinary retention\", \"urinary incontinence\", \"kidney stones\",\n",
        "    \"renal failure\", \"hematuria\", \"proteinuria\", \"dysuria\",\n",
        "    \"impotence\", \"decreased libido\", \"menstrual irregularities\",\n",
        "    \"breast tenderness\", \"gynecomastia\", \"hyperglycemia\", \"hypoglycemia\",\n",
        "    \"electrolyte imbalance\", \"thyroid dysfunction\", \"increased cholesterol\",\n",
        "    \"dehydration\", \"diabetes\", \"hyperthyroidism\", \"hypothyroidism\",\n",
        "    \"taste changes\", \"visual disturbances\", \"hearing loss\", \"tinnitus\",\n",
        "    \"anaphylaxis\", \"allergic reactions\", \"fat redistribution\", \"hepatotoxicity\",\n",
        "    \"cardiotoxicity\", \"nephrotoxicity\", \"neurotoxicity\", \"ototoxicity\",\n",
        "    \"musculoskeletal pain\", \"bone pain\", \"osteoporosis\"\n",
        "]\n",
        "\n",
        "# Tokenisation\n",
        "tokens = word_tokenize(big_text)\n",
        "\n",
        "effect_terms_count = Counter([word for word in tokens if word in effects_list])\n",
        "\n",
        "# Le nuage de mots avec tous les termes trouvés\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate_from_frequencies(effect_terms_count)\n",
        "wordcloud.to_file(\"wordcloud.png\")\n",
        "\n",
        "# Analyseur de sentiments\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "df_posts['sentiment'] = df_posts['Content'].apply(lambda x: sia.polarity_scores(x)['compound'] if isinstance(x, str) else 0)\n",
        "\n",
        "# Classification des sentiments\n",
        "def classify_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return 'positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df_posts['sentiment_class'] = df_posts['sentiment'].apply(classify_sentiment)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHq_o5Js_ku6",
        "outputId": "5ea6fc8b-9562-4ba1-fd17-3bb041895807"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dash"
      ],
      "metadata": {
        "id": "AtfsuJDDA2_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your images\n",
        "wordcloud_path = \"/content/wordcloud.png\"\n",
        "logo_path = \"/content/logo.jpeg\"\n",
        "\n",
        "# Convert images to base64\n",
        "encoded_wordcloud = base64.b64encode(open(wordcloud_path, 'rb').read()).decode('ascii')\n",
        "encoded_logo = base64.b64encode(open(logo_path, 'rb').read()).decode('ascii')\n",
        "\n",
        "# Dash\n",
        "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
        "\n",
        "# Mise en page de l'application\n",
        "app.layout = dbc.Container([\n",
        "    dbc.Navbar(\n",
        "        dbc.Container([\n",
        "            html.Img(src=f'data:image/jpeg;base64,{encoded_logo}', height=\"40px\"),\n",
        "            dbc.NavbarBrand(\n",
        "                \"Déclarations des effets indésirables associés aux médicaments de alzeimer\",\n",
        "                className=\"ms-2\"\n",
        "            ),\n",
        "            dbc.NavbarToggler(id=\"navbar-toggler\"),\n",
        "            dbc.Collapse(\n",
        "                dbc.Nav(\n",
        "                    [\n",
        "                        dbc.NavItem(dbc.NavLink(\"Accueil\", href=\"/\")),\n",
        "                        dbc.NavItem(dbc.NavLink(\"ANSM\", href=\"/ansm\")),\n",
        "                        dbc.NavItem(dbc.NavLink(\"Forum Alzheimer\", href=\"/forum\")),\n",
        "                    ],\n",
        "                    className=\"ms-auto\",\n",
        "                    navbar=True\n",
        "                ),\n",
        "                id=\"navbar-collapse\",\n",
        "                navbar=True,\n",
        "            ),\n",
        "        ]),\n",
        "        color=\"primary\",\n",
        "        dark=True,\n",
        "    ),\n",
        "    dcc.Location(id='url', refresh=False),\n",
        "    html.Div(id='page-content')\n",
        "], fluid=True)\n",
        "\n",
        "# Page d'accueil\n",
        "# Home Page\n",
        "home_page = dbc.Container([\n",
        "    html.Div([\n",
        "        html.H3(\"Projet\"),\n",
        "        html.P(\"Le projet consiste en plusieurs étapes clés : collecte des données, analyse des sentiments, et visualisation des résultats. \"\n",
        "               \"La collecte des données est effectuée par web scraping des forums spécialisés, suivi par une analyse de sentiments pour comprendre les perceptions des utilisateurs. \"\n",
        "               \"Les résultats sont ensuite présentés sous forme de graphiques interactifs pour une interprétation facile.\"),\n",
        "        html.Hr(),  # Add a horizontal rule for separation\n",
        "        html.H3(\"Word Cloud des Effets Indésirables\"),\n",
        "        dbc.Card(\n",
        "            dbc.CardBody(\n",
        "                html.Div(\n",
        "                    html.Img(src=f'data:image/png;base64,{encoded_wordcloud}', style={'width': '100%'}),\n",
        "                    style={'display': 'flex', 'justify-content': 'center'}\n",
        "                )\n",
        "            ),\n",
        "            className=\"mt-3\"\n",
        "        ),\n",
        "        html.Hr(),  # Add a horizontal rule for separation\n",
        "        html.H3(\"Design du Projet\"),\n",
        "        html.P(\"Le design du projet est axé sur la simplicité et l'accessibilité. Les données sont présentées de manière claire et concise pour garantir que \"\n",
        "               \"les informations importantes sont facilement compréhensibles par tous les utilisateurs. Les graphiques interactifs permettent d'explorer les données \"\n",
        "               \"en détail et de mieux comprendre les tendances et les sentiments associés aux médicaments.\")\n",
        "    ])\n",
        "], fluid=True)\n",
        "\n",
        "# Page ANSM\n",
        "ansm_page = dbc.Container([\n",
        "    html.H3(\"Sélectionner un Médicament\"),\n",
        "    dcc.Dropdown(\n",
        "        id='medicament-dropdown',\n",
        "        options=[{'label': nom, 'value': nom} for nom in df_sex_distribution['Nom_du_médicament'].unique()],\n",
        "        value=df_sex_distribution['Nom_du_médicament'].unique()[0]  # Valeur par défaut\n",
        "    ),\n",
        "    dbc.Row([\n",
        "        dbc.Col(dcc.Graph(id='sex-distribution'), width=6),\n",
        "        dbc.Col(dcc.Graph(id='age-distribution'), width=6)\n",
        "    ]),\n",
        "    dbc.Row([\n",
        "        dbc.Col(dcc.Graph(id='effects-distribution'), width=12)\n",
        "    ])\n",
        "], fluid=True)\n",
        "\n",
        "# Page Forum\n",
        "forum_page = dbc.Container([\n",
        "    dbc.Row([\n",
        "        dbc.Col(dcc.Graph(id='sentiment-bar-chart'), width=6),\n",
        "        dbc.Col(dcc.Graph(id='sentiment-box-plot'), width=6)\n",
        "    ])\n",
        "], fluid=True)\n",
        "\n",
        "# Mise à jour du contenu en fonction de l'URL\n",
        "@app.callback(Output('page-content', 'children'),\n",
        "              [Input('url', 'pathname')])\n",
        "def display_page(pathname):\n",
        "    if pathname == '/ansm':\n",
        "        return ansm_page\n",
        "    elif pathname == '/forum':\n",
        "        return forum_page\n",
        "    else:\n",
        "        return home_page\n",
        "\n",
        "# Callbacks pour mettre à jour les graphiques de la page ANSM\n",
        "@app.callback(\n",
        "    Output('sex-distribution', 'figure'),\n",
        "    Output('age-distribution', 'figure'),\n",
        "    Output('effects-distribution', 'figure'),\n",
        "    Input('medicament-dropdown', 'value')\n",
        ")\n",
        "def update_ansm_graphs(selected_medicament):\n",
        "    filtered_sex_df = df_sex_distribution[df_sex_distribution['Nom_du_médicament'] == selected_medicament]\n",
        "    filtered_age_df = df_age_distribution[df_age_distribution['Nom_du_médicament'] == selected_medicament]\n",
        "    filtered_effects_df = df_effects_count[df_effects_count['Nom_du_médicament'] == selected_medicament]\n",
        "\n",
        "    fig_sex = px.bar(filtered_sex_df, x='Nom_du_médicament', y=['Hommes (%)', 'Femmes (%)'],\n",
        "                     title=f'Répartition des Patients par Sexe pour {selected_medicament}', barmode='group',\n",
        "                     color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    age_data = filtered_age_df.melt(id_vars=[\"Nom_du_médicament\"], value_vars=['20-59 (%)', '60+ (%)'],\n",
        "                                    var_name=\"Tranche d'âge\", value_name=\"Pourcentage\")\n",
        "    fig_age = px.pie(age_data, names='Tranche d\\'âge', values='Pourcentage',\n",
        "                     title=f'Répartition des Patients par Tranche d\\'Âge pour {selected_medicament}',\n",
        "                     color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    df_effects_sum = filtered_effects_df.groupby('Pathologie')['Valeur'].sum().reset_index()\n",
        "    fig_effects = px.pie(df_effects_sum, values='Valeur', names='Pathologie',\n",
        "                         title=f'Types d\\'Effets Indésirables pour {selected_medicament}',\n",
        "                         color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    return fig_sex, fig_age, fig_effects\n",
        "\n",
        "# Analyseur de sentiments\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "df_posts['sentiment'] = df_posts['Content'].apply(lambda x: sia.polarity_scores(x)['compound'] if isinstance(x, str) else 0)\n",
        "\n",
        "# Classification des sentiments\n",
        "def classify_sentiment(score):\n",
        "    if score >= 0.05:\n",
        "        return 'positive'\n",
        "    elif score <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "df_posts['sentiment_class'] = df_posts['sentiment'].apply(classify_sentiment)\n",
        "\n",
        "# Visualisation des sentiments\n",
        "sentiment_counts = df_posts['sentiment_class'].value_counts().reset_index()\n",
        "sentiment_counts.columns = ['sentiment_class', 'count']\n",
        "\n",
        "# Callbacks pour mettre à jour les graphiques de la page Forum\n",
        "@app.callback(\n",
        "    Output('sentiment-bar-chart', 'figure'),\n",
        "    Output('sentiment-box-plot', 'figure'),\n",
        "    Input('url', 'pathname')\n",
        ")\n",
        "def update_forum_graphs(pathname):\n",
        "    fig_bar = px.bar(sentiment_counts, x='sentiment_class', y='count',\n",
        "                     title='Distribution des Sentiments dans les Posts du Forum',\n",
        "                     color='sentiment_class', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    fig_box = px.box(df_posts, x='sentiment_class', y='sentiment',\n",
        "                     title='Scores de Sentiment par Classe de Sentiment',\n",
        "                     color='sentiment_class', color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "    return fig_bar, fig_box\n",
        "\n",
        "# Exécutation l'application\n",
        "nest_asyncio.apply()\n",
        "app.run_server(mode='inline', height=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "ulGOHQ61FpSW",
        "outputId": "68d63d65-5b9c-4b90-a39d-e4a504f65708"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}